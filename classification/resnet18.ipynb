{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import imutils\n",
    "import matplotlib.image as mpimg\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from skimage import io, transform\n",
    "from math import *\n",
    "import xml.etree.ElementTree as ET \n",
    "import pandas as pd\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from skimage.transform import rotate as rotate_transform\n",
    "from skimage.util import random_noise\n",
    "from skimage.filters import gaussian\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "\n",
    "class Transforms():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def rotate(self, image, params):\n",
    "\n",
    "        angle = params['rotation_range'][0]\n",
    "        angle = (random.uniform(0,1))*random.choice([-1,1])*angle\n",
    "        transformation_matrix = torch.tensor([\n",
    "            [+cos(radians(angle)), -sin(radians(angle))], \n",
    "            [+sin(radians(angle)), +cos(radians(angle))]\n",
    "        ])\n",
    "\n",
    "        image = rotate_transform(np.array(image), angle = angle, mode = 'edge')\n",
    "\n",
    "        # PIL expects RGB images to be uint with ranges from 0 to 255 so we have to convert it to a type that PIL can excpect ie a uint from 0 to 255 \n",
    "        return Image.fromarray((image * 255).astype(np.uint8))\n",
    "\n",
    "    def translation(self, image,  params):\n",
    "        image_shape = np.array(image).shape\n",
    "        ty = random.uniform(params['height_shift_range'][0]*image_shape[0],          \n",
    "                            params['height_shift_range'][1]*image_shape[0])\n",
    "        tx = random.uniform(params['width_shift_range'][0]*image_shape[1],\n",
    "                            params['width_shift_range'][1]*image_shape[1] )\n",
    "\n",
    "        \n",
    "        horizontal_shift =  tx*random.choice([-1,1])\n",
    "        vertical_shift = ty*random.choice([-1,1])\n",
    "        horizontal_shift_normalised = horizontal_shift/image_shape[1]\n",
    "        vertical_shift_normalised =  vertical_shift/image_shape[0]\n",
    "\n",
    "        transform = AffineTransform(translation=(-horizontal_shift,-vertical_shift))\n",
    "\n",
    "        image = warp(np.array(image),transform,mode='edge')\n",
    "\n",
    "\n",
    "  \n",
    "        # PIL expects RGB images to be uint with ranges from 0 to 255 so we have to convert it to a type that PIL can excpect ie a uint from 0 to 255 \n",
    "        return Image.fromarray((image * 255).astype(np.uint8))\n",
    "        \n",
    "    def resize(self, image, img_size):\n",
    "        image = TF.resize(image, img_size)\n",
    "        return image\n",
    "\n",
    "    def zoom(self, image, params):\n",
    "\n",
    "        img_shape = np.array(image).shape\n",
    "        zoom = random.uniform(params['zoom_range'][0],params['zoom_range'][1])\n",
    "        image = TF.resize(image,(int(img_shape[0]*zoom), int(img_shape[1]*zoom)) )\n",
    "        scale_transform = torch.tensor([[zoom, 0], \n",
    "                                        [0, zoom]])\n",
    "\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def color_jitter(self, image):\n",
    "        color_jitter = transforms.ColorJitter(brightness=0.3, \n",
    "                                              contrast=0.3,\n",
    "                                              saturation=0.3, \n",
    "                                              hue=0.1)\n",
    "        image = color_jitter(image)\n",
    "        return image\n",
    "\n",
    "\n",
    "    def __call__(self, image, params, image_size):\n",
    "\n",
    "        # set checked image and landmark to landmark_ and image_ (this is for making sure we use the last checked tranformed instead of wrongly tranformed to do the following               # tranform)\n",
    "        \n",
    "        # -----------------------\n",
    "        image_ = Image.fromarray(image.copy())\n",
    "\n",
    "        # -----------------------\n",
    "\n",
    "        # ZOOM\n",
    "        image  = self.zoom(image_,  params)\n",
    "        \n",
    "\n",
    "        # RESIZE\n",
    "\n",
    "        image = self.resize(image, (image_size, image_size))\n",
    "\n",
    "        # ----------------------\n",
    "        #image_, landmarks_ = self.color_jitter(image_, landmarks_)\n",
    "        # ----------------------\n",
    "        \n",
    "        # ROTATE\n",
    "        image = self.rotate(image,  params)\n",
    "\n",
    "\n",
    "        # ----------------------\n",
    "\n",
    "        image = image\n",
    "        # ----------------------\n",
    "\n",
    "        # TRANSLATION\n",
    "        image= self.translation(image, params)\n",
    "\n",
    " \n",
    "        \n",
    "        image = TF.to_tensor(image)\n",
    "        # the following tranform normalises each channel to have a mean at 0.5 and std of 0.5 / NOTE: NOT sure if this is theoreticlly better, should check this\n",
    "        image = TF.normalize(image, [0.5], [0.5])\n",
    "        return image\n",
    "\n",
    "class LandmarksDataset():\n",
    "\n",
    "    def __init__(self, transform=None,zoom = [1.0 - 0.03258157476873315, 1.0 + 0.03258157476873315], rotation = [22], height_shift= [0,0.03003200603616672], width_shift= [0,0.03003200603616672 ]):\n",
    "\n",
    "        # targets 0\n",
    "        filenames1 = os.listdir('D:/Tsetse fly Project/Data/Missing_landmarkwings_L/')\n",
    "        #filenames2 = os.listdir('D:/Tsetse fly Project/Data/Missing_landmarkwings_R/')\n",
    "        # targets 1\n",
    "        filenames3 = os.listdir('C:/Users/dylan/Desktop/goodwingsv20-21/')\n",
    "    \n",
    "        self. tranform = transform\n",
    "        self.zoom = zoom\n",
    "        self.rotation = rotation\n",
    "        self.height_shift = height_shift\n",
    "        self.width_shift = width_shift\n",
    "        self.image_filenames = []\n",
    "        self.targets = []\n",
    "        self.image_size = 244\n",
    "        self.transform = transform\n",
    "        self.image_dir = 'D:/Tsetse fly Project/Data/Missing_landmarkwings_L/'\n",
    "        \n",
    "        #self.image_dir2 = 'D:/Tsetse fly Project/Data/Missing_landmarkwings_R/'\n",
    "        self.image_dir3 = 'C:/Users/dylan/Desktop/goodwingsv20-21/'\n",
    "        self.TransF_ = True\n",
    "\n",
    "       # ------------------- Append left wings data to dataset class ------------\n",
    "\n",
    "        for filename in filenames1:\n",
    "            self.image_filenames.append(os.path.join(self.image_dir, filename))\n",
    "            self.targets.append(1)\n",
    "\n",
    "            \n",
    "\n",
    "        # ------------------ Append flipped right wings data to dataset class-----\n",
    "\n",
    "\n",
    "        #for filename in filenames2[:]:\n",
    "        #    self.targets.append(1)\n",
    "        #    self.image_filenames.append(os.path.join(self.image_dir2, filename))\n",
    "\n",
    "        #num = len(self.targets.copy())\n",
    "        for filename in filenames3:\n",
    "            self.targets.append(0)\n",
    "            self.image_filenames.append(os.path.join(self.image_dir3, filename))\n",
    "\n",
    "\n",
    "\n",
    "        # ----------------------\n",
    "\n",
    "    def TransF(self):\n",
    "        self.TransF_ = True\n",
    "    def NoTransF(self):\n",
    "        self.TransF_ = False\n",
    "    def resize(self,size):\n",
    "        self.image_size = size\n",
    "    def set_params(self, zoom = [0.95, 0.105], rotation = [10], height_shift= [0,0.05], width_shift= [0,0.05]):\n",
    "        self.zoom = zoom\n",
    "        self.rotation = rotation\n",
    "        self.height_shift = height_shift\n",
    "        self.width_shift = width_shift\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        params = {'zoom_range': self.zoom, 'rotation_range':self.rotation, 'height_shift_range': self.height_shift, 'width_shift_range': self.width_shift }\n",
    "        image_ = plt.imread(self.image_filenames[index])\n",
    "        target = torch.tensor(self.targets[index])\n",
    "\n",
    "        image = plt.imread(self.image_filenames[index])\n",
    "\n",
    "        \n",
    "        if self.transform and self.TransF_:\n",
    "            \n",
    "            image = self.transform(image_, params, self.image_size)\n",
    "\n",
    "        else:\n",
    "            img_shape = image.copy().shape\n",
    "            image = Image.fromarray(image)\n",
    "            image = TF.resize(image, (self.image_size,self.image_size))\n",
    "       \n",
    "            image = TF.to_tensor(image)\n",
    "            # the following tranform normalises each channel to have a mean at 0.5 and std of 0.5 / NOTE: NOT sure if this is theoreticlly better, should check this\n",
    "            image = TF.normalize(image, [0.5], [0.5])\n",
    "\n",
    "        return image, target\n",
    "\n",
    "DataSet = LandmarksDataset(Transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet18_(nn.Module):\n",
    "    def __init__(self,num_classes=1):\n",
    "        super().__init__()\n",
    "        self.model_name='resnet18'\n",
    "        self.model=models.resnet18(pretrained = True)\n",
    "        self.model.conv1=nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.model.fc=nn.Linear(self.model.fc.in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=torch.sigmoid(self.model(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, y):\n",
    "    return(sum((predictions.round() == y)) / float(len(y))).item()\n",
    "\n",
    "    # helper functions\n",
    "import sys\n",
    "\n",
    "def print_overwrite(step, total_step, loss, operation):\n",
    "    sys.stdout.write('\\r')\n",
    "    if operation == 'train':\n",
    "        sys.stdout.write(\"Train Steps: %d/%d  Loss: %.6f \" % (step, total_step, loss))   \n",
    "    else:\n",
    "        sys.stdout.write(\"Valid Steps: %d/%d  Loss: %.6f \" % (step, total_step, loss))\n",
    "        \n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of Train set is 842\n",
      "The length of Valid set is 280\n",
      "The length of Valid set is 280\n"
     ]
    }
   ],
   "source": [
    "DataSet.TransF()\n",
    "DataSet.resize(244)\n",
    "dataset = DataSet\n",
    "# split the dataset into validation and test sets\n",
    "len_valid_test_set = int(0.2*len(dataset)) # 60% training, 20% validation, 20% testing\n",
    "\n",
    "len_train_set = len(dataset) - len_valid_test_set*2\n",
    "\n",
    "print(\"The length of Train set is {}\".format(len_train_set))\n",
    "print(\"The length of Valid set is {}\".format(len_valid_test_set))\n",
    "print(\"The length of Valid set is {}\".format(len_valid_test_set))\n",
    "\n",
    "train_dataset , valid_dataset, test_dataset  = torch.utils.data.random_split(dataset , [len_train_set, len_valid_test_set, len_valid_test_set], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# shuffle and batch the datasets\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=20, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Steps: 14/14  Loss: 0.684294 \n",
      "--------------------------------------------------\n",
      "Epoch: 1  Train Loss: 0.3848  Valid Loss: 0.6843\n",
      "--------------------------------------------------\n",
      "Epoch: 1  Train acc: 0.81176  Valid acc: 0.55357\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.6843 at epoch 1/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 14/14  Loss: 0.392730 \n",
      "--------------------------------------------------\n",
      "Epoch: 2  Train Loss: 0.1009  Valid Loss: 0.3927\n",
      "--------------------------------------------------\n",
      "Epoch: 2  Train acc: 0.96000  Valid acc: 0.81786\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.3927 at epoch 2/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 14/14  Loss: 0.146286 \n",
      "--------------------------------------------------\n",
      "Epoch: 3  Train Loss: 0.0796  Valid Loss: 0.1463\n",
      "--------------------------------------------------\n",
      "Epoch: 3  Train acc: 0.97059  Valid acc: 0.95000\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.1463 at epoch 3/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 14/14  Loss: 0.160253 \n",
      "--------------------------------------------------\n",
      "Epoch: 4  Train Loss: 0.0444  Valid Loss: 0.1603\n",
      "--------------------------------------------------\n",
      "Epoch: 4  Train acc: 0.98471  Valid acc: 0.96071\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.044489 \n",
      "--------------------------------------------------\n",
      "Epoch: 5  Train Loss: 0.0314  Valid Loss: 0.0445\n",
      "--------------------------------------------------\n",
      "Epoch: 5  Train acc: 0.99059  Valid acc: 0.98571\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0445 at epoch 5/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 14/14  Loss: 0.061384 \n",
      "--------------------------------------------------\n",
      "Epoch: 6  Train Loss: 0.0212  Valid Loss: 0.0614\n",
      "--------------------------------------------------\n",
      "Epoch: 6  Train acc: 0.99294  Valid acc: 0.98214\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.155793 \n",
      "--------------------------------------------------\n",
      "Epoch: 7  Train Loss: 0.0131  Valid Loss: 0.1558\n",
      "--------------------------------------------------\n",
      "Epoch: 7  Train acc: 0.99647  Valid acc: 0.94286\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.080087 \n",
      "--------------------------------------------------\n",
      "Epoch: 8  Train Loss: 0.0085  Valid Loss: 0.0801\n",
      "--------------------------------------------------\n",
      "Epoch: 8  Train acc: 0.99765  Valid acc: 0.96429\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.155505 \n",
      "--------------------------------------------------\n",
      "Epoch: 9  Train Loss: 0.0136  Valid Loss: 0.1555\n",
      "--------------------------------------------------\n",
      "Epoch: 9  Train acc: 0.99647  Valid acc: 0.93571\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.074233 \n",
      "--------------------------------------------------\n",
      "Epoch: 10  Train Loss: 0.0168  Valid Loss: 0.0742\n",
      "--------------------------------------------------\n",
      "Epoch: 10  Train acc: 0.99176  Valid acc: 0.97500\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.034566 \n",
      "--------------------------------------------------\n",
      "Epoch: 11  Train Loss: 0.0147  Valid Loss: 0.0346\n",
      "--------------------------------------------------\n",
      "Epoch: 11  Train acc: 0.99412  Valid acc: 0.98571\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0346 at epoch 11/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 14/14  Loss: 0.032358 \n",
      "--------------------------------------------------\n",
      "Epoch: 12  Train Loss: 0.0145  Valid Loss: 0.0324\n",
      "--------------------------------------------------\n",
      "Epoch: 12  Train acc: 0.99529  Valid acc: 0.98571\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0324 at epoch 12/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 14/14  Loss: 0.041890 \n",
      "--------------------------------------------------\n",
      "Epoch: 13  Train Loss: 0.0142  Valid Loss: 0.0419\n",
      "--------------------------------------------------\n",
      "Epoch: 13  Train acc: 0.99765  Valid acc: 0.98214\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.030452 \n",
      "--------------------------------------------------\n",
      "Epoch: 14  Train Loss: 0.0099  Valid Loss: 0.0305\n",
      "--------------------------------------------------\n",
      "Epoch: 14  Train acc: 0.99765  Valid acc: 0.98929\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0305 at epoch 14/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 14/14  Loss: 0.038179 \n",
      "--------------------------------------------------\n",
      "Epoch: 15  Train Loss: 0.0085  Valid Loss: 0.0382\n",
      "--------------------------------------------------\n",
      "Epoch: 15  Train acc: 0.99882  Valid acc: 0.98929\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.032821 \n",
      "--------------------------------------------------\n",
      "Epoch: 16  Train Loss: 0.0057  Valid Loss: 0.0328\n",
      "--------------------------------------------------\n",
      "Epoch: 16  Train acc: 1.00000  Valid acc: 0.98214\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.028308 \n",
      "--------------------------------------------------\n",
      "Epoch: 17  Train Loss: 0.0052  Valid Loss: 0.0283\n",
      "--------------------------------------------------\n",
      "Epoch: 17  Train acc: 0.99882  Valid acc: 0.98929\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0283 at epoch 17/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 14/14  Loss: 0.040467 \n",
      "--------------------------------------------------\n",
      "Epoch: 18  Train Loss: 0.0037  Valid Loss: 0.0405\n",
      "--------------------------------------------------\n",
      "Epoch: 18  Train acc: 0.99882  Valid acc: 0.98214\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.053970 \n",
      "--------------------------------------------------\n",
      "Epoch: 19  Train Loss: 0.0036  Valid Loss: 0.0540\n",
      "--------------------------------------------------\n",
      "Epoch: 19  Train acc: 1.00000  Valid acc: 0.98214\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.019407 \n",
      "--------------------------------------------------\n",
      "Epoch: 20  Train Loss: 0.0018  Valid Loss: 0.0194\n",
      "--------------------------------------------------\n",
      "Epoch: 20  Train acc: 1.00000  Valid acc: 0.98571\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0194 at epoch 20/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 14/14  Loss: 0.062542 \n",
      "--------------------------------------------------\n",
      "Epoch: 21  Train Loss: 0.0100  Valid Loss: 0.0625\n",
      "--------------------------------------------------\n",
      "Epoch: 21  Train acc: 0.99647  Valid acc: 0.98214\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.011934 \n",
      "--------------------------------------------------\n",
      "Epoch: 22  Train Loss: 0.0071  Valid Loss: 0.0119\n",
      "--------------------------------------------------\n",
      "Epoch: 22  Train acc: 0.99882  Valid acc: 0.99643\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0119 at epoch 22/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 14/14  Loss: 0.045123 \n",
      "--------------------------------------------------\n",
      "Epoch: 23  Train Loss: 0.0104  Valid Loss: 0.0451\n",
      "--------------------------------------------------\n",
      "Epoch: 23  Train acc: 0.99647  Valid acc: 0.97857\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.034973 \n",
      "--------------------------------------------------\n",
      "Epoch: 24  Train Loss: 0.0066  Valid Loss: 0.0350\n",
      "--------------------------------------------------\n",
      "Epoch: 24  Train acc: 0.99882  Valid acc: 0.98214\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.065019 \n",
      "--------------------------------------------------\n",
      "Epoch: 25  Train Loss: 0.0028  Valid Loss: 0.0650\n",
      "--------------------------------------------------\n",
      "Epoch: 25  Train acc: 1.00000  Valid acc: 0.97857\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.053927 \n",
      "--------------------------------------------------\n",
      "Epoch: 26  Train Loss: 0.0064  Valid Loss: 0.0539\n",
      "--------------------------------------------------\n",
      "Epoch: 26  Train acc: 0.99882  Valid acc: 0.97500\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.038326 \n",
      "--------------------------------------------------\n",
      "Epoch: 27  Train Loss: 0.0012  Valid Loss: 0.0383\n",
      "--------------------------------------------------\n",
      "Epoch: 27  Train acc: 1.00000  Valid acc: 0.98929\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.023999 \n",
      "--------------------------------------------------\n",
      "Epoch: 28  Train Loss: 0.0045  Valid Loss: 0.0240\n",
      "--------------------------------------------------\n",
      "Epoch: 28  Train acc: 0.99882  Valid acc: 0.99286\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.076772 \n",
      "--------------------------------------------------\n",
      "Epoch: 29  Train Loss: 0.0234  Valid Loss: 0.0768\n",
      "--------------------------------------------------\n",
      "Epoch: 29  Train acc: 0.98941  Valid acc: 0.98214\n",
      "--------------------------------------------------\n",
      "Valid Steps: 14/14  Loss: 0.022426 \n",
      "--------------------------------------------------\n",
      "Epoch: 30  Train Loss: 0.0069  Valid Loss: 0.0224\n",
      "--------------------------------------------------\n",
      "Epoch: 30  Train acc: 0.99765  Valid acc: 0.98929\n",
      "--------------------------------------------------\n",
      "Training Complete\n",
      "Total Elapsed Time : 5400.7176632881165 s\n"
     ]
    }
   ],
   "source": [
    "# feature transfer learning (none of th weights are frozen)\n",
    "\n",
    "results = {'acc_train': [], 'acc_val': [], 'loss_train': [], 'loss_val':[], 'time': []}\n",
    "network = resnet18_().cuda()\n",
    "\n",
    "# TRAIN\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.0001)\n",
    "loss_min = np.inf\n",
    "num_epochs = 30\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    acc_train = 0\n",
    "    acc_valid = 0\n",
    "    running_acc = 0\n",
    "    loss_train = 0\n",
    "    loss_valid = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    network.train()\n",
    "    for step in range(1,len(train_loader)+1):\n",
    "\n",
    "        images, targets = next(iter(train_loader))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda().float() \n",
    "    \n",
    "        predictions = network(images).flatten()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        \n",
    "        # find the loss for the current step\n",
    "    \n",
    "        loss_train_step = criterion(predictions, targets)\n",
    "\n",
    "\n",
    "        acc_train_step = accuracy(predictions, targets)\n",
    "\n",
    "        \n",
    "        # calculate the gradients\n",
    "\n",
    "        loss_train_step.backward()\n",
    "    \n",
    "        \n",
    "        # update the parameters\n",
    "\n",
    "        optimizer.step()\n",
    "        acc_train += acc_train_step\n",
    "        loss_train += loss_train_step.item()\n",
    "\n",
    "        running_acc  = acc_train/step\n",
    "        running_loss = loss_train/step\n",
    "\n",
    "        \n",
    "        print_overwrite(step, len(train_loader), running_loss, 'train')\n",
    "        \n",
    "    network.eval() \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for step in range(1,len(valid_loader)+1):\n",
    "            \n",
    "            \n",
    "            images, targets = next(iter(valid_loader))\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "                targets = targets.cuda().float()\n",
    "        \n",
    "            predictions = network(images).flatten()\n",
    "\n",
    "            # find the loss for the current step\n",
    "            loss_valid_step = criterion(predictions, targets)\n",
    "\n",
    "            acc_valid_step = accuracy(predictions, targets)\n",
    "   \n",
    "            acc_valid += acc_valid_step\n",
    "  \n",
    "            running_acc = acc_valid/step\n",
    "            loss_valid += loss_valid_step.item()\n",
    "            running_loss = loss_valid/step\n",
    "\n",
    "            print_overwrite(step, len(valid_loader), running_loss, 'valid')\n",
    "    \n",
    "    loss_train /= len(train_loader)\n",
    "    loss_valid /= len(valid_loader)\n",
    "    acc_train /= len(train_loader)\n",
    "    acc_valid /= len(valid_loader)\n",
    "    \n",
    "    \n",
    "    print('\\n--------------------------------------------------')\n",
    "    print('Epoch: {}  Train Loss: {:.4f}  Valid Loss: {:.4f}'.format(epoch, loss_train, loss_valid))\n",
    "    print('--------------------------------------------------')\n",
    "    print('Epoch: {}  Train acc: {:.5f}  Valid acc: {:.5f}'.format(epoch, acc_train, acc_valid))\n",
    "    print('--------------------------------------------------')\n",
    "    results['loss_train'].append(loss_train)\n",
    "    results['loss_val'].append(loss_valid)\n",
    "    results['acc_train'].append(acc_train)\n",
    "    results['acc_val'].append(acc_valid)\n",
    "\n",
    "    if loss_valid < loss_min:\n",
    "        loss_min = loss_valid\n",
    "        torch.save(network.state_dict(), 'C:/Users/dylan/Work-Projects/msc_haar/manuscript1_exp/classifiers/models/model_resnet18_classifer_finetune.pth') \n",
    "        print(\"\\nMinimum Validation Loss of {:.4f} at epoch {}/{}\".format(loss_min, epoch, num_epochs))\n",
    "        print('Model Saved\\n')\n",
    "print('Training Complete')\n",
    "print(\"Total Elapsed Time : {} s\".format(time.time()-start_time))\n",
    "results['time'].append(time.time()-start_time)\n",
    "del(network)\n",
    "del(images)\n",
    "del(targets)\n",
    "del(predictions)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import pickle\n",
    "f = open(\"C:/Users/dylan/Work-Projects/msc_haar/manuscript1_exp/classifiers/training_losses/model_resnet18_classifer_finetune_trainingdata.pkl\",\"wb\")\n",
    "pickle.dump(results,f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Steps: 11/11  Loss: 0.633360 \n",
      "--------------------------------------------------\n",
      "Epoch: 1  Train Loss: 0.4295  Valid Loss: 0.6334\n",
      "--------------------------------------------------\n",
      "Epoch: 1  Train acc: 0.79714  Valid acc: 0.63182\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.6334 at epoch 1/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 11/11  Loss: 0.880317 \n",
      "--------------------------------------------------\n",
      "Epoch: 2  Train Loss: 0.1689  Valid Loss: 0.8803\n",
      "--------------------------------------------------\n",
      "Epoch: 2  Train acc: 0.93714  Valid acc: 0.56364\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.274628 \n",
      "--------------------------------------------------\n",
      "Epoch: 3  Train Loss: 0.1079  Valid Loss: 0.2746\n",
      "--------------------------------------------------\n",
      "Epoch: 3  Train acc: 0.96143  Valid acc: 0.87727\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.2746 at epoch 3/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 11/11  Loss: 0.080676 \n",
      "--------------------------------------------------\n",
      "Epoch: 4  Train Loss: 0.0751  Valid Loss: 0.0807\n",
      "--------------------------------------------------\n",
      "Epoch: 4  Train acc: 0.97714  Valid acc: 0.97727\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0807 at epoch 4/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 11/11  Loss: 0.100961 \n",
      "--------------------------------------------------\n",
      "Epoch: 5  Train Loss: 0.0789  Valid Loss: 0.1010\n",
      "--------------------------------------------------\n",
      "Epoch: 5  Train acc: 0.97714  Valid acc: 0.97273\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.065112 \n",
      "--------------------------------------------------\n",
      "Epoch: 6  Train Loss: 0.0487  Valid Loss: 0.0651\n",
      "--------------------------------------------------\n",
      "Epoch: 6  Train acc: 0.98714  Valid acc: 0.98182\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0651 at epoch 6/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 11/11  Loss: 0.098217 \n",
      "--------------------------------------------------\n",
      "Epoch: 7  Train Loss: 0.0326  Valid Loss: 0.0982\n",
      "--------------------------------------------------\n",
      "Epoch: 7  Train acc: 0.99143  Valid acc: 0.97273\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.074669 \n",
      "--------------------------------------------------\n",
      "Epoch: 8  Train Loss: 0.0485  Valid Loss: 0.0747\n",
      "--------------------------------------------------\n",
      "Epoch: 8  Train acc: 0.98000  Valid acc: 0.97273\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.051504 \n",
      "--------------------------------------------------\n",
      "Epoch: 9  Train Loss: 0.0446  Valid Loss: 0.0515\n",
      "--------------------------------------------------\n",
      "Epoch: 9  Train acc: 0.99000  Valid acc: 0.98636\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0515 at epoch 9/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 11/11  Loss: 0.110847 \n",
      "--------------------------------------------------\n",
      "Epoch: 10  Train Loss: 0.0253  Valid Loss: 0.1108\n",
      "--------------------------------------------------\n",
      "Epoch: 10  Train acc: 0.99143  Valid acc: 0.97273\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.040632 \n",
      "--------------------------------------------------\n",
      "Epoch: 11  Train Loss: 0.0483  Valid Loss: 0.0406\n",
      "--------------------------------------------------\n",
      "Epoch: 11  Train acc: 0.98571  Valid acc: 0.99091\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0406 at epoch 11/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 11/11  Loss: 0.116336 \n",
      "--------------------------------------------------\n",
      "Epoch: 12  Train Loss: 0.0327  Valid Loss: 0.1163\n",
      "--------------------------------------------------\n",
      "Epoch: 12  Train acc: 0.99143  Valid acc: 0.96364\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.092168 \n",
      "--------------------------------------------------\n",
      "Epoch: 13  Train Loss: 0.0366  Valid Loss: 0.0922\n",
      "--------------------------------------------------\n",
      "Epoch: 13  Train acc: 0.98571  Valid acc: 0.96818\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.090037 \n",
      "--------------------------------------------------\n",
      "Epoch: 14  Train Loss: 0.0430  Valid Loss: 0.0900\n",
      "--------------------------------------------------\n",
      "Epoch: 14  Train acc: 0.98429  Valid acc: 0.97727\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.038241 \n",
      "--------------------------------------------------\n",
      "Epoch: 15  Train Loss: 0.0304  Valid Loss: 0.0382\n",
      "--------------------------------------------------\n",
      "Epoch: 15  Train acc: 0.99286  Valid acc: 0.99545\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0382 at epoch 15/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 11/11  Loss: 0.067615 \n",
      "--------------------------------------------------\n",
      "Epoch: 16  Train Loss: 0.0128  Valid Loss: 0.0676\n",
      "--------------------------------------------------\n",
      "Epoch: 16  Train acc: 0.99714  Valid acc: 0.97727\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.046159 \n",
      "--------------------------------------------------\n",
      "Epoch: 17  Train Loss: 0.0087  Valid Loss: 0.0462\n",
      "--------------------------------------------------\n",
      "Epoch: 17  Train acc: 1.00000  Valid acc: 0.98182\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.057154 \n",
      "--------------------------------------------------\n",
      "Epoch: 18  Train Loss: 0.0178  Valid Loss: 0.0572\n",
      "--------------------------------------------------\n",
      "Epoch: 18  Train acc: 0.99571  Valid acc: 0.98182\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.130677 \n",
      "--------------------------------------------------\n",
      "Epoch: 19  Train Loss: 0.0069  Valid Loss: 0.1307\n",
      "--------------------------------------------------\n",
      "Epoch: 19  Train acc: 0.99857  Valid acc: 0.97727\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.035610 \n",
      "--------------------------------------------------\n",
      "Epoch: 20  Train Loss: 0.0178  Valid Loss: 0.0356\n",
      "--------------------------------------------------\n",
      "Epoch: 20  Train acc: 0.99286  Valid acc: 0.99545\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0356 at epoch 20/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 11/11  Loss: 0.053430 \n",
      "--------------------------------------------------\n",
      "Epoch: 21  Train Loss: 0.0095  Valid Loss: 0.0534\n",
      "--------------------------------------------------\n",
      "Epoch: 21  Train acc: 0.99714  Valid acc: 0.98636\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.069678 \n",
      "--------------------------------------------------\n",
      "Epoch: 22  Train Loss: 0.0214  Valid Loss: 0.0697\n",
      "--------------------------------------------------\n",
      "Epoch: 22  Train acc: 0.99429  Valid acc: 0.97727\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.088793 \n",
      "--------------------------------------------------\n",
      "Epoch: 23  Train Loss: 0.0095  Valid Loss: 0.0888\n",
      "--------------------------------------------------\n",
      "Epoch: 23  Train acc: 0.99571  Valid acc: 0.98182\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.051843 \n",
      "--------------------------------------------------\n",
      "Epoch: 24  Train Loss: 0.0097  Valid Loss: 0.0518\n",
      "--------------------------------------------------\n",
      "Epoch: 24  Train acc: 0.99714  Valid acc: 0.98636\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.135829 \n",
      "--------------------------------------------------\n",
      "Epoch: 25  Train Loss: 0.0153  Valid Loss: 0.1358\n",
      "--------------------------------------------------\n",
      "Epoch: 25  Train acc: 0.99143  Valid acc: 0.95909\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.072655 \n",
      "--------------------------------------------------\n",
      "Epoch: 26  Train Loss: 0.0102  Valid Loss: 0.0727\n",
      "--------------------------------------------------\n",
      "Epoch: 26  Train acc: 0.99429  Valid acc: 0.97727\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.171898 \n",
      "--------------------------------------------------\n",
      "Epoch: 27  Train Loss: 0.0132  Valid Loss: 0.1719\n",
      "--------------------------------------------------\n",
      "Epoch: 27  Train acc: 0.99429  Valid acc: 0.95000\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.055686 \n",
      "--------------------------------------------------\n",
      "Epoch: 28  Train Loss: 0.0071  Valid Loss: 0.0557\n",
      "--------------------------------------------------\n",
      "Epoch: 28  Train acc: 0.99714  Valid acc: 0.97727\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.058964 \n",
      "--------------------------------------------------\n",
      "Epoch: 29  Train Loss: 0.0077  Valid Loss: 0.0590\n",
      "--------------------------------------------------\n",
      "Epoch: 29  Train acc: 0.99714  Valid acc: 0.97273\n",
      "--------------------------------------------------\n",
      "Valid Steps: 11/11  Loss: 0.042065 \n",
      "--------------------------------------------------\n",
      "Epoch: 30  Train Loss: 0.0059  Valid Loss: 0.0421\n",
      "--------------------------------------------------\n",
      "Epoch: 30  Train acc: 1.00000  Valid acc: 0.98636\n",
      "--------------------------------------------------\n",
      "Training Complete\n",
      "Total Elapsed Time : 4041.9732887744904 s\n"
     ]
    }
   ],
   "source": [
    "# feature transfer learning (none of th weights are frozen)\n",
    "\n",
    "results = {'acc_train': [], 'acc_val': [], 'loss_train': [], 'loss_val':[], 'time': []}\n",
    "network = resnet18_().cuda()\n",
    "\n",
    "# TRAIN\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.0001)\n",
    "loss_min = np.inf\n",
    "num_epochs = 30\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    acc_train = 0\n",
    "    acc_valid = 0\n",
    "    running_acc = 0\n",
    "    loss_train = 0\n",
    "    loss_valid = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    network.train()\n",
    "    for step in range(1,len(train_loader)+1):\n",
    "\n",
    "        images, targets = next(iter(train_loader))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda().float() \n",
    "    \n",
    "        predictions = network(images).flatten()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        \n",
    "        # find the loss for the current step\n",
    "    \n",
    "        loss_train_step = criterion(predictions, targets)\n",
    "\n",
    "\n",
    "        acc_train_step = accuracy(predictions, targets)\n",
    "\n",
    "        \n",
    "        # calculate the gradients\n",
    "\n",
    "        loss_train_step.backward()\n",
    "    \n",
    "        \n",
    "        # update the parameters\n",
    "\n",
    "        optimizer.step()\n",
    "        acc_train += acc_train_step\n",
    "        loss_train += loss_train_step.item()\n",
    "\n",
    "        running_acc  = acc_train/step\n",
    "        running_loss = loss_train/step\n",
    "\n",
    "        \n",
    "        print_overwrite(step, len(train_loader), running_loss, 'train')\n",
    "        \n",
    "    network.eval() \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for step in range(1,len(valid_loader)+1):\n",
    "            \n",
    "            \n",
    "            images, targets = next(iter(valid_loader))\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "                targets = targets.cuda().float()\n",
    "        \n",
    "            predictions = network(images).flatten()\n",
    "\n",
    "            # find the loss for the current step\n",
    "            loss_valid_step = criterion(predictions, targets)\n",
    "\n",
    "            acc_valid_step = accuracy(predictions, targets)\n",
    "   \n",
    "            acc_valid += acc_valid_step\n",
    "  \n",
    "            running_acc = acc_valid/step\n",
    "            loss_valid += loss_valid_step.item()\n",
    "            running_loss = loss_valid/step\n",
    "\n",
    "            print_overwrite(step, len(valid_loader), running_loss, 'valid')\n",
    "    \n",
    "    loss_train /= len(train_loader)\n",
    "    loss_valid /= len(valid_loader)\n",
    "    acc_train /= len(train_loader)\n",
    "    acc_valid /= len(valid_loader)\n",
    "    \n",
    "    \n",
    "    print('\\n--------------------------------------------------')\n",
    "    print('Epoch: {}  Train Loss: {:.4f}  Valid Loss: {:.4f}'.format(epoch, loss_train, loss_valid))\n",
    "    print('--------------------------------------------------')\n",
    "    print('Epoch: {}  Train acc: {:.5f}  Valid acc: {:.5f}'.format(epoch, acc_train, acc_valid))\n",
    "    print('--------------------------------------------------')\n",
    "    results['loss_train'].append(loss_train)\n",
    "    results['loss_val'].append(loss_valid)\n",
    "    results['acc_train'].append(acc_train)\n",
    "    results['acc_val'].append(acc_valid)\n",
    "\n",
    "    if loss_valid < loss_min:\n",
    "        loss_min = loss_valid\n",
    "        torch.save(network.state_dict(), 'C:/Users/dylan/Work-Projects/msc_haar/manuscript1_exp/models/model_resnet18_classifer_finetune2.pth') \n",
    "        print(\"\\nMinimum Validation Loss of {:.4f} at epoch {}/{}\".format(loss_min, epoch, num_epochs))\n",
    "        print('Model Saved\\n')\n",
    "print('Training Complete')\n",
    "print(\"Total Elapsed Time : {} s\".format(time.time()-start_time))\n",
    "results['time'].append(time.time()-start_time)\n",
    "del(network)\n",
    "del(images)\n",
    "del(targets)\n",
    "del(predictions)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import pickle\n",
    "f = open(\"model_resnet18_classifer_finetune_trainingdata2.pkl\",\"wb\")\n",
    "pickle.dump(results,f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"model_resnet18_classifer_finetune_trainingdata.pkl\",\"wb\")\n",
    "pickle.dump(results,f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Steps: 2/14  Loss: 0.763188 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c63b69a66590>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dylan\\Work-Projects\\msc_haar\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dylan\\Work-Projects\\msc_haar\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dylan\\Work-Projects\\msc_haar\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dylan\\Work-Projects\\msc_haar\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dylan\\Work-Projects\\msc_haar\\env\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-085e19fbf18b>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTransF_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-085e19fbf18b>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, image, params, image_size)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# -----------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mimage_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;31m# -----------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# feature transfer learning (none of th weights are frozen)\n",
    "\n",
    "results = {'acc_train': [], 'acc_val': [], 'loss_train': [], 'loss_val':[], 'time': []}\n",
    "network = resnet18_().cuda()\n",
    "for param in network.model.parameters():\n",
    "    param.requires_grad = False\n",
    "in_features_fc = network.model.fc.in_features \n",
    "network.model.fc = nn.Linear(in_features_fc, out_features=1, bias=True)\n",
    "# TRAIN\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(network.parameters())\n",
    "loss_min = np.inf\n",
    "num_epochs = 50\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    acc_train = 0\n",
    "    acc_valid = 0\n",
    "    running_acc = 0\n",
    "    loss_train = 0\n",
    "    loss_valid = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    network.train()\n",
    "    for step in range(1,len(train_loader)+1):\n",
    "\n",
    "        images, targets = next(iter(train_loader))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda().float() \n",
    "    \n",
    "        predictions = network(images).flatten()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        \n",
    "        # find the loss for the current step\n",
    "    \n",
    "        loss_train_step = criterion(predictions, targets)\n",
    "\n",
    "\n",
    "        acc_train_step = accuracy(predictions, targets)\n",
    "\n",
    "\n",
    "        \n",
    "        # calculate the gradients\n",
    "\n",
    "        loss_train_step.backward()\n",
    "    \n",
    "        \n",
    "        # update the parameters\n",
    "\n",
    "        optimizer.step()\n",
    "        acc_train += acc_train_step\n",
    "        loss_train += loss_train_step.item()\n",
    "        \n",
    "        running_acc  = acc_train/step\n",
    "        running_loss = loss_train/step\n",
    "\n",
    "        \n",
    "        print_overwrite(step, len(train_loader), running_loss, 'train')\n",
    "        \n",
    "    network.eval() \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for step in range(1,len(valid_loader)+1):\n",
    "            \n",
    "            \n",
    "            images, targets = next(iter(valid_loader))\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "                targets = targets.cuda().float()\n",
    "        \n",
    "            predictions = network(images).flatten()\n",
    "\n",
    "            # find the loss for the current step\n",
    "            loss_valid_step = criterion(predictions, targets)\n",
    "\n",
    "            acc_valid_step = accuracy(predictions, targets)\n",
    "\n",
    "            acc_valid += acc_valid_step\n",
    "            running_acc = acc_valid/step\n",
    "            loss_valid += loss_valid_step.item()\n",
    "            running_loss = loss_valid/step\n",
    "\n",
    "            print_overwrite(step, len(valid_loader), running_loss, 'valid')\n",
    "    \n",
    "    loss_train /= len(train_loader)\n",
    "    loss_valid /= len(valid_loader)\n",
    "    acc_train /= len(train_loader)\n",
    "    acc_valid /= len(train_loader)\n",
    "    \n",
    "    \n",
    "    print('\\n--------------------------------------------------')\n",
    "    print('Epoch: {}  Train Loss: {:.4f}  Valid Loss: {:.4f}'.format(epoch, loss_train, loss_valid))\n",
    "    print('--------------------------------------------------')\n",
    "    results['loss_train'].append(loss_train)\n",
    "    results['loss_train'].append(loss_valid)\n",
    "    results['acc_train'].append(acc_train)\n",
    "    results['acc_val'].append(acc_valid)\n",
    "\n",
    "    if loss_valid < loss_min:\n",
    "        loss_min = loss_valid\n",
    "        torch.save(network.state_dict(), 'C:/Users/dylan/Work-Projects/msc_haar/manuscript1_exp/models/model_resnet18_classifer_fixedfeatures.pth') \n",
    "        print(\"\\nMinimum Validation Loss of {:.4f} at epoch {}/{}\".format(loss_min, epoch, num_epochs))\n",
    "        print('Model Saved\\n')\n",
    "print('Training Complete')\n",
    "print(\"Total Elapsed Time : {} s\".format(time.time()-start_time))\n",
    "results['time'].append(time.time()-start_time)\n",
    "del(network)\n",
    "del(images)\n",
    "del(targets)\n",
    "del(predictions)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "f = open(\"model_resnet18_classifer_fixedfeatures_trainingdata.pkl\",\"wb\")\n",
    "pickle.dump(results,f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "7ec889e55d6cc5b8bc0c6d4c97764aa47dfaa2c194dbff749325c0fada24bc92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
