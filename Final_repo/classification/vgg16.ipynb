{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import imutils\n",
    "import matplotlib.image as mpimg\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import io, transform\n",
    "from math import * \n",
    "import xml.etree.ElementTree as ET \n",
    "import pandas as pd\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from skimage.transform import rotate as rotate_transform\n",
    "from skimage.util import random_noise\n",
    "from skimage.filters import gaussian\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Transforms():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def rotate(self, image, params):\n",
    "\n",
    "        angle = params['rotation_range'][0]\n",
    "        angle = (random.uniform(0,1))*random.choice([-1,1])*angle\n",
    "        transformation_matrix = torch.tensor([\n",
    "            [+cos(radians(angle)), -sin(radians(angle))], \n",
    "            [+sin(radians(angle)), +cos(radians(angle))]\n",
    "        ])\n",
    "\n",
    "        image = rotate_transform(np.array(image), angle = angle, mode = 'edge')\n",
    "\n",
    "        # PIL expects RGB images to be uint with ranges from 0 to 255 so we have to convert it to a type that PIL can excpect ie a uint from 0 to 255 \n",
    "        return Image.fromarray((image * 255).astype(np.uint8))\n",
    "\n",
    "    def translation(self, image,  params):\n",
    "        image_shape = np.array(image).shape\n",
    "        ty = random.uniform(params['height_shift_range'][0]*image_shape[0],          \n",
    "                            params['height_shift_range'][1]*image_shape[0])\n",
    "        tx = random.uniform(params['width_shift_range'][0]*image_shape[1],\n",
    "                            params['width_shift_range'][1]*image_shape[1] )\n",
    "\n",
    "        \n",
    "        horizontal_shift =  tx*random.choice([-1,1])\n",
    "        vertical_shift = ty*random.choice([-1,1])\n",
    "        horizontal_shift_normalised = horizontal_shift/image_shape[1]\n",
    "        vertical_shift_normalised =  vertical_shift/image_shape[0]\n",
    "\n",
    "        transform = AffineTransform(translation=(-horizontal_shift,-vertical_shift))\n",
    "\n",
    "        image = warp(np.array(image),transform,mode='edge')\n",
    "\n",
    "\n",
    "  \n",
    "        # PIL expects RGB images to be uint with ranges from 0 to 255 so we have to convert it to a type that PIL can excpect ie a uint from 0 to 255 \n",
    "        return Image.fromarray((image * 255).astype(np.uint8))\n",
    "        \n",
    "    def resize(self, image, img_size):\n",
    "        image = TF.resize(image, img_size)\n",
    "        return image\n",
    "\n",
    "    def zoom(self, image, params):\n",
    "\n",
    "        img_shape = np.array(image).shape\n",
    "        zoom = random.uniform(params['zoom_range'][0],params['zoom_range'][1])\n",
    "        image = TF.resize(image,(int(img_shape[0]*zoom), int(img_shape[1]*zoom)) )\n",
    "        scale_transform = torch.tensor([[zoom, 0], \n",
    "                                        [0, zoom]])\n",
    "\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def color_jitter(self, image):\n",
    "        color_jitter = transforms.ColorJitter(brightness=0.3, \n",
    "                                              contrast=0.3,\n",
    "                                              saturation=0.3, \n",
    "                                              hue=0.1)\n",
    "        image = color_jitter(image)\n",
    "        return image\n",
    "\n",
    "\n",
    "    def __call__(self, image, params, image_size):\n",
    "\n",
    "        # set checked image and landmark to landmark_ and image_ (this is for making sure we use the last checked tranformed instead of wrongly tranformed to do the following               # tranform)\n",
    "        \n",
    "        # -----------------------\n",
    "        image_ = Image.fromarray(image.copy())\n",
    "\n",
    "        # -----------------------\n",
    "\n",
    "        # ZOOM\n",
    "        image  = self.zoom(image_,  params)\n",
    "        \n",
    "\n",
    "        # RESIZE\n",
    "\n",
    "        image = self.resize(image, (image_size, image_size))\n",
    "\n",
    "        # ----------------------\n",
    "        #image_, landmarks_ = self.color_jitter(image_, landmarks_)\n",
    "        # ----------------------\n",
    "        \n",
    "        # ROTATE\n",
    "        image = self.rotate(image,  params)\n",
    "\n",
    "\n",
    "        # ----------------------\n",
    "\n",
    "        image = image\n",
    "        # ----------------------\n",
    "\n",
    "        # TRANSLATION\n",
    "        image= self.translation(image, params)\n",
    "\n",
    " \n",
    "        \n",
    "        image = TF.to_tensor(image)\n",
    "        # the following tranform normalises each channel to have a mean at 0.5 and std of 0.5 / NOTE: NOT sure if this is theoreticlly better, should check this\n",
    "        image = TF.normalize(image, [0.5], [0.5])\n",
    "        return image\n",
    "\n",
    "class LandmarksDataset():\n",
    "\n",
    "    def __init__(self, transform=None,zoom = [1.0 - 0.03258157476873315, 1.0 + 0.03258157476873315], rotation = [22], height_shift= [0,0.03003200603616672], width_shift= [0,0.03003200603616672 ]):\n",
    "\n",
    "        # targets 0\n",
    "        filenames1 = os.listdir('D:/Tsetse fly Project/Data/Missing_landmarkwings_L/')\n",
    "        #filenames2 = os.listdir('D:/Tsetse fly Project/Data/Missing_landmarkwings_R/')\n",
    "        # targets 1\n",
    "        filenames3 = os.listdir('C:/Users/dylan/Desktop/goodwingsv20-21/')\n",
    "    \n",
    "        self. tranform = transform\n",
    "        self.zoom = zoom\n",
    "        self.rotation = rotation\n",
    "        self.height_shift = height_shift\n",
    "        self.width_shift = width_shift\n",
    "        self.image_filenames = []\n",
    "        self.targets = []\n",
    "        self.image_size = 224\n",
    "        self.transform = transform\n",
    "        self.image_dir = 'D:/Tsetse fly Project/Data/Missing_landmarkwings_L/'\n",
    "        \n",
    "        #self.image_dir2 = 'D:/Tsetse fly Project/Data/Missing_landmarkwings_R/'\n",
    "        self.image_dir3 = 'C:/Users/dylan/Desktop/goodwingsv20-21/'\n",
    "        self.TransF_ = True\n",
    "\n",
    "       # ------------------- Append left wings data to dataset class ------------\n",
    "\n",
    "        for filename in filenames1:\n",
    "            self.image_filenames.append(os.path.join(self.image_dir, filename))\n",
    "            self.targets.append(1)\n",
    "\n",
    "            \n",
    "\n",
    "        # ------------------ Append flipped right wings data to dataset class-----\n",
    "\n",
    "\n",
    "        #for filename in filenames2[:]:\n",
    "        #    self.targets.append(1)\n",
    "        #    self.image_filenames.append(os.path.join(self.image_dir2, filename))\n",
    "\n",
    "        #num = len(self.targets.copy())\n",
    "        for filename in filenames3:\n",
    "            self.targets.append(0)\n",
    "            self.image_filenames.append(os.path.join(self.image_dir3, filename))\n",
    "\n",
    "\n",
    "\n",
    "        # ----------------------\n",
    "\n",
    "    def TransF(self):\n",
    "        self.TransF_ = True\n",
    "    def NoTransF(self):\n",
    "        self.TransF_ = False\n",
    "    def resize(self,size):\n",
    "        self.image_size = size\n",
    "    def set_params(self, zoom = [0.95, 0.105], rotation = [10], height_shift= [0,0.05], width_shift= [0,0.05]):\n",
    "        self.zoom = zoom\n",
    "        self.rotation = rotation\n",
    "        self.height_shift = height_shift\n",
    "        self.width_shift = width_shift\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        params = {'zoom_range': self.zoom, 'rotation_range':self.rotation, 'height_shift_range': self.height_shift, 'width_shift_range': self.width_shift }\n",
    "        image_ = plt.imread(self.image_filenames[index])\n",
    "        target = torch.tensor(self.targets[index])\n",
    "\n",
    "        image = plt.imread(self.image_filenames[index])\n",
    "\n",
    "        \n",
    "        if self.transform and self.TransF_:\n",
    "            \n",
    "            image = self.transform(image_, params, self.image_size)\n",
    "\n",
    "        else:\n",
    "            img_shape = image.copy().shape\n",
    "            image = Image.fromarray(image)\n",
    "            image = TF.resize(image, (self.image_size,self.image_size))\n",
    "       \n",
    "            image = TF.to_tensor(image)\n",
    "            # the following tranform normalises each channel to have a mean at 0.5 and std of 0.5 / NOTE: NOT sure if this is theoreticlly better, should check this\n",
    "            image = TF.normalize(image, [0.5], [0.5])\n",
    "\n",
    "        return image, target\n",
    "\n",
    "DataSet = LandmarksDataset(Transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg16_bn_(nn.Module):\n",
    "    def __init__(self,num_classes=1):\n",
    "        super().__init__()\n",
    "        self.model_name='vgg16_bn'\n",
    "        self.model=models.vgg16_bn(pretrained=True)\n",
    "        #self.model.conv1=nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.model.classifier=nn.Linear(self.model.classifier[0].in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.model(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = vgg16_bn_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vgg16_bn_(\n",
       "  (model): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (36): ReLU(inplace=True)\n",
       "      (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (39): ReLU(inplace=True)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace=True)\n",
       "      (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Linear(in_features=25088, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, y):\n",
    "    return(sum((predictions.round() == y)) / float(len(y))).item()\n",
    "\n",
    "\n",
    "    # helper functions\n",
    "import sys\n",
    "\n",
    "def print_overwrite(step, total_step, loss, operation):\n",
    "    sys.stdout.write('\\r')\n",
    "    if operation == 'train':\n",
    "        sys.stdout.write(\"Train Steps: %d/%d  Loss: %.6f \" % (step, total_step, loss))   \n",
    "    else:\n",
    "        sys.stdout.write(\"Valid Steps: %d/%d  Loss: %.6f \" % (step, total_step, loss))\n",
    "        \n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of Train set is 842\n",
      "The length of Valid set is 280\n",
      "The length of Valid set is 280\n"
     ]
    }
   ],
   "source": [
    "DataSet.TransF()\n",
    "DataSet.resize(224)\n",
    "dataset = DataSet\n",
    "# split the dataset into validation and test sets\n",
    "len_valid_test_set = int(0.2*len(dataset)) # 60% training, 20% validation, 20% testing\n",
    "\n",
    "len_train_set = len(dataset) - len_valid_test_set*2\n",
    "\n",
    "print(\"The length of Train set is {}\".format(len_train_set))\n",
    "print(\"The length of Valid set is {}\".format(len_valid_test_set))\n",
    "print(\"The length of Valid set is {}\".format(len_valid_test_set))\n",
    "\n",
    "train_dataset , valid_dataset, test_dataset  = torch.utils.data.random_split(dataset , [len_train_set, len_valid_test_set, len_valid_test_set], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# shuffle and batch the datasets\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=15, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=15, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=15, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Steps: 19/19  Loss: 0.074139 \n",
      "--------------------------------------------------\n",
      "Epoch: 1  Train Loss: 0.2037  Valid Loss: 0.0741\n",
      "--------------------------------------------------\n",
      "Epoch: 1  Train acc: 0.91462  Valid acc: 0.98246\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0741 at epoch 1/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 19/19  Loss: 0.059763 \n",
      "--------------------------------------------------\n",
      "Epoch: 2  Train Loss: 0.0148  Valid Loss: 0.0598\n",
      "--------------------------------------------------\n",
      "Epoch: 2  Train acc: 0.99415  Valid acc: 0.98596\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0598 at epoch 2/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 19/19  Loss: 0.044017 \n",
      "--------------------------------------------------\n",
      "Epoch: 3  Train Loss: 0.0032  Valid Loss: 0.0440\n",
      "--------------------------------------------------\n",
      "Epoch: 3  Train acc: 1.00000  Valid acc: 0.98947\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0440 at epoch 3/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 19/19  Loss: 0.005171 \n",
      "--------------------------------------------------\n",
      "Epoch: 4  Train Loss: 0.0012  Valid Loss: 0.0052\n",
      "--------------------------------------------------\n",
      "Epoch: 4  Train acc: 1.00000  Valid acc: 1.00000\n",
      "--------------------------------------------------\n",
      "\n",
      "Minimum Validation Loss of 0.0052 at epoch 4/30\n",
      "Model Saved\n",
      "\n",
      "Valid Steps: 19/19  Loss: 0.026932 \n",
      "--------------------------------------------------\n",
      "Epoch: 5  Train Loss: 0.0267  Valid Loss: 0.0269\n",
      "--------------------------------------------------\n",
      "Epoch: 5  Train acc: 0.98947  Valid acc: 0.99298\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.067495 \n",
      "--------------------------------------------------\n",
      "Epoch: 6  Train Loss: 0.0154  Valid Loss: 0.0675\n",
      "--------------------------------------------------\n",
      "Epoch: 6  Train acc: 0.99649  Valid acc: 0.97544\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.020653 \n",
      "--------------------------------------------------\n",
      "Epoch: 7  Train Loss: 0.0044  Valid Loss: 0.0207\n",
      "--------------------------------------------------\n",
      "Epoch: 7  Train acc: 0.99883  Valid acc: 0.98947\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.011166 \n",
      "--------------------------------------------------\n",
      "Epoch: 8  Train Loss: 0.0063  Valid Loss: 0.0112\n",
      "--------------------------------------------------\n",
      "Epoch: 8  Train acc: 0.99883  Valid acc: 0.99298\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.035159 \n",
      "--------------------------------------------------\n",
      "Epoch: 9  Train Loss: 0.0103  Valid Loss: 0.0352\n",
      "--------------------------------------------------\n",
      "Epoch: 9  Train acc: 0.99766  Valid acc: 0.98246\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.022817 \n",
      "--------------------------------------------------\n",
      "Epoch: 10  Train Loss: 0.0032  Valid Loss: 0.0228\n",
      "--------------------------------------------------\n",
      "Epoch: 10  Train acc: 0.99766  Valid acc: 0.99649\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.008170 \n",
      "--------------------------------------------------\n",
      "Epoch: 11  Train Loss: 0.0009  Valid Loss: 0.0082\n",
      "--------------------------------------------------\n",
      "Epoch: 11  Train acc: 1.00000  Valid acc: 0.99649\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.015695 \n",
      "--------------------------------------------------\n",
      "Epoch: 12  Train Loss: 0.0009  Valid Loss: 0.0157\n",
      "--------------------------------------------------\n",
      "Epoch: 12  Train acc: 1.00000  Valid acc: 0.99649\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.009110 \n",
      "--------------------------------------------------\n",
      "Epoch: 13  Train Loss: 0.0002  Valid Loss: 0.0091\n",
      "--------------------------------------------------\n",
      "Epoch: 13  Train acc: 1.00000  Valid acc: 0.99649\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.016925 \n",
      "--------------------------------------------------\n",
      "Epoch: 14  Train Loss: 0.0129  Valid Loss: 0.0169\n",
      "--------------------------------------------------\n",
      "Epoch: 14  Train acc: 0.99649  Valid acc: 1.00000\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.022369 \n",
      "--------------------------------------------------\n",
      "Epoch: 15  Train Loss: 0.0012  Valid Loss: 0.0224\n",
      "--------------------------------------------------\n",
      "Epoch: 15  Train acc: 1.00000  Valid acc: 0.99298\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.015122 \n",
      "--------------------------------------------------\n",
      "Epoch: 16  Train Loss: 0.0003  Valid Loss: 0.0151\n",
      "--------------------------------------------------\n",
      "Epoch: 16  Train acc: 1.00000  Valid acc: 0.99298\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.034298 \n",
      "--------------------------------------------------\n",
      "Epoch: 17  Train Loss: 0.0007  Valid Loss: 0.0343\n",
      "--------------------------------------------------\n",
      "Epoch: 17  Train acc: 1.00000  Valid acc: 0.98947\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.014977 \n",
      "--------------------------------------------------\n",
      "Epoch: 18  Train Loss: 0.0002  Valid Loss: 0.0150\n",
      "--------------------------------------------------\n",
      "Epoch: 18  Train acc: 1.00000  Valid acc: 0.99298\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.025379 \n",
      "--------------------------------------------------\n",
      "Epoch: 19  Train Loss: 0.0001  Valid Loss: 0.0254\n",
      "--------------------------------------------------\n",
      "Epoch: 19  Train acc: 1.00000  Valid acc: 0.99298\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.055723 \n",
      "--------------------------------------------------\n",
      "Epoch: 20  Train Loss: 0.0010  Valid Loss: 0.0557\n",
      "--------------------------------------------------\n",
      "Epoch: 20  Train acc: 0.99883  Valid acc: 0.98596\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.010398 \n",
      "--------------------------------------------------\n",
      "Epoch: 21  Train Loss: 0.0112  Valid Loss: 0.0104\n",
      "--------------------------------------------------\n",
      "Epoch: 21  Train acc: 0.99532  Valid acc: 0.99649\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.007996 \n",
      "--------------------------------------------------\n",
      "Epoch: 22  Train Loss: 0.0008  Valid Loss: 0.0080\n",
      "--------------------------------------------------\n",
      "Epoch: 22  Train acc: 1.00000  Valid acc: 0.99298\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.026623 \n",
      "--------------------------------------------------\n",
      "Epoch: 23  Train Loss: 0.0004  Valid Loss: 0.0266\n",
      "--------------------------------------------------\n",
      "Epoch: 23  Train acc: 1.00000  Valid acc: 0.98947\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.060530 \n",
      "--------------------------------------------------\n",
      "Epoch: 24  Train Loss: 0.0003  Valid Loss: 0.0605\n",
      "--------------------------------------------------\n",
      "Epoch: 24  Train acc: 1.00000  Valid acc: 0.97895\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.068511 \n",
      "--------------------------------------------------\n",
      "Epoch: 25  Train Loss: 0.0007  Valid Loss: 0.0685\n",
      "--------------------------------------------------\n",
      "Epoch: 25  Train acc: 1.00000  Valid acc: 0.97544\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.052306 \n",
      "--------------------------------------------------\n",
      "Epoch: 26  Train Loss: 0.0240  Valid Loss: 0.0523\n",
      "--------------------------------------------------\n",
      "Epoch: 26  Train acc: 0.99181  Valid acc: 0.98596\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.049211 \n",
      "--------------------------------------------------\n",
      "Epoch: 27  Train Loss: 0.0147  Valid Loss: 0.0492\n",
      "--------------------------------------------------\n",
      "Epoch: 27  Train acc: 0.99649  Valid acc: 0.98246\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.051835 \n",
      "--------------------------------------------------\n",
      "Epoch: 28  Train Loss: 0.0114  Valid Loss: 0.0518\n",
      "--------------------------------------------------\n",
      "Epoch: 28  Train acc: 0.99766  Valid acc: 0.98947\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.009788 \n",
      "--------------------------------------------------\n",
      "Epoch: 29  Train Loss: 0.0017  Valid Loss: 0.0098\n",
      "--------------------------------------------------\n",
      "Epoch: 29  Train acc: 1.00000  Valid acc: 0.99649\n",
      "--------------------------------------------------\n",
      "Valid Steps: 19/19  Loss: 0.034658 \n",
      "--------------------------------------------------\n",
      "Epoch: 30  Train Loss: 0.0007  Valid Loss: 0.0347\n",
      "--------------------------------------------------\n",
      "Epoch: 30  Train acc: 1.00000  Valid acc: 0.99298\n",
      "--------------------------------------------------\n",
      "Training Complete\n",
      "Total Elapsed Time : 6310.346856355667 s\n"
     ]
    }
   ],
   "source": [
    "# feature transfer learning (none of th weights are frozen)\n",
    "\n",
    "results = {'acc_train': [], 'acc_val': [], 'loss_train': [], 'loss_val':[], 'time': []}\n",
    "network = vgg16_bn_().cuda()\n",
    "\n",
    "# TRAIN\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(network.parameters(), lr = 0.0001)\n",
    "loss_min = np.inf\n",
    "num_epochs = 30\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    acc_train = 0\n",
    "    acc_valid = 0\n",
    "    running_acc = 0\n",
    "    loss_train = 0\n",
    "    loss_valid = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    network.train()\n",
    "    for step in range(1,len(train_loader)+1):\n",
    "\n",
    "        images, targets = next(iter(train_loader))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda().float() \n",
    "    \n",
    "        predictions = network(images).flatten()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        \n",
    "        # find the loss for the current step\n",
    "    \n",
    "        loss_train_step = criterion(predictions, targets)\n",
    "\n",
    "\n",
    "        acc_train_step = accuracy(predictions, targets)\n",
    "\n",
    "\n",
    "        \n",
    "        # calculate the gradients\n",
    "\n",
    "        loss_train_step.backward()\n",
    "    \n",
    "        \n",
    "        # update the parameters\n",
    "\n",
    "        optimizer.step()\n",
    "        acc_train += acc_train_step\n",
    "        loss_train += loss_train_step.item()\n",
    "        \n",
    "        running_acc  = acc_train/step\n",
    "        running_loss = loss_train/step\n",
    "\n",
    "        \n",
    "        print_overwrite(step, len(train_loader), running_loss, 'train')\n",
    "        \n",
    "    network.eval() \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for step in range(1,len(valid_loader)+1):\n",
    "            \n",
    "            \n",
    "            images, targets = next(iter(valid_loader))\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "                targets = targets.cuda().float()\n",
    "        \n",
    "            predictions = network(images).flatten()\n",
    "\n",
    "            # find the loss for the current step\n",
    "            loss_valid_step = criterion(predictions, targets)\n",
    "\n",
    "            acc_valid_step = accuracy(predictions, targets)\n",
    "\n",
    "            acc_valid += acc_valid_step\n",
    "            running_acc = acc_valid/step\n",
    "            loss_valid += loss_valid_step.item()\n",
    "            running_loss = loss_valid/step\n",
    "\n",
    "            print_overwrite(step, len(valid_loader), running_loss, 'valid')\n",
    "    \n",
    "    loss_train /= len(train_loader)\n",
    "    loss_valid /= len(valid_loader)\n",
    "    acc_train /= len(train_loader)\n",
    "    acc_valid /= len(valid_loader)\n",
    "    \n",
    "    \n",
    "    print('\\n--------------------------------------------------')\n",
    "    print('Epoch: {}  Train Loss: {:.4f}  Valid Loss: {:.4f}'.format(epoch, loss_train, loss_valid))\n",
    "    print('--------------------------------------------------')\n",
    "    print('Epoch: {}  Train acc: {:.5f}  Valid acc: {:.5f}'.format(epoch, acc_train, acc_valid))\n",
    "    print('--------------------------------------------------')\n",
    "    results['loss_train'].append(loss_train)\n",
    "    results['loss_val'].append(loss_valid)\n",
    "    results['acc_train'].append(acc_train)\n",
    "    results['acc_val'].append(acc_valid)\n",
    "\n",
    "    if loss_valid < loss_min:\n",
    "        loss_min = loss_valid\n",
    "        torch.save(network.state_dict(), 'C:/Users/dylan/Work-Projects/msc_haar/manuscript1_exp/classifiers/models/model_vgg16_bn_classifer_finetune2.pth') \n",
    "        print(\"\\nMinimum Validation Loss of {:.4f} at epoch {}/{}\".format(loss_min, epoch, num_epochs))\n",
    "        print('Model Saved\\n')\n",
    "print('Training Complete')\n",
    "print(\"Total Elapsed Time : {} s\".format(time.time()-start_time))\n",
    "results['time'].append(time.time()-start_time)\n",
    "del(network)\n",
    "del(images)\n",
    "del(targets)\n",
    "del(predictions)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "f = open(\"C:/Users/dylan/Work-Projects/msc_haar/manuscript1_exp/classifiers/training_losses/model_vgg16_bn_classifer_finetune_trainingdata2.pkl\",\"wb\")\n",
    "pickle.dump(results,f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature transfer learning (weights are frozen)\n",
    "\n",
    "results = {'acc_train': [], 'acc_val': [], 'loss_train': [], 'loss_val':[], 'time': []}\n",
    "network = vgg16_bn_().cuda()\n",
    "for param in network.model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "# TRAIN\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(network.parameters(), )\n",
    "loss_min = np.inf\n",
    "num_epochs = 50\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    acc_train = 0\n",
    "    acc_valid = 0\n",
    "    running_acc = 0\n",
    "    loss_train = 0\n",
    "    loss_valid = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    network.train()\n",
    "    for step in range(1,len(train_loader)+1):\n",
    "\n",
    "        images, targets = next(iter(train_loader))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda().float() \n",
    "    \n",
    "        predictions = network(images).flatten()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        \n",
    "        # find the loss for the current step\n",
    "    \n",
    "        loss_train_step = criterion(predictions, targets)\n",
    "\n",
    "\n",
    "        acc_train_step = accuracy(predictions, targets)\n",
    "\n",
    "\n",
    "        \n",
    "        # calculate the gradients\n",
    "\n",
    "        loss_train_step.backward()\n",
    "    \n",
    "        \n",
    "        # update the parameters\n",
    "\n",
    "        optimizer.step()\n",
    "        acc_train += acc_train_step\n",
    "        loss_train += loss_train_step.item()\n",
    "        \n",
    "        running_acc  = acc_train/step\n",
    "        running_loss = loss_train/step\n",
    "\n",
    "        \n",
    "        print_overwrite(step, len(train_loader), running_loss, 'train')\n",
    "        \n",
    "    network.eval() \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for step in range(1,len(valid_loader)+1):\n",
    "            \n",
    "            \n",
    "            images, targets = next(iter(valid_loader))\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "                targets = targets.cuda().float()\n",
    "        \n",
    "            predictions = network(images).flatten()\n",
    "\n",
    "            # find the loss for the current step\n",
    "            loss_valid_step = criterion(predictions, targets)\n",
    "\n",
    "            acc_valid_step = accuracy(predictions, targets)\n",
    "\n",
    "            acc_valid += acc_valid_step\n",
    "            running_acc = acc_valid/step\n",
    "            loss_valid += loss_valid_step.item()\n",
    "            running_loss = loss_valid/step\n",
    "\n",
    "            print_overwrite(step, len(valid_loader), running_loss, 'valid')\n",
    "    \n",
    "    loss_train /= len(train_loader)\n",
    "    loss_valid /= len(valid_loader)\n",
    "    acc_train /= len(train_loader)\n",
    "    acc_valid /= len(train_loader)\n",
    "    \n",
    "    \n",
    "    print('\\n--------------------------------------------------')\n",
    "    print('Epoch: {}  Train Loss: {:.4f}  Valid Loss: {:.4f}'.format(epoch, loss_train, loss_valid))\n",
    "    print('--------------------------------------------------')\n",
    "    results['loss_train'].append(loss_train)\n",
    "    results['loss_train'].append(loss_valid)\n",
    "    results['acc_train'].append(acc_train)\n",
    "    results['acc_val'].append(acc_valid)\n",
    "\n",
    "    if loss_valid < loss_min:\n",
    "        loss_min = loss_valid\n",
    "        torch.save(network.state_dict(), 'C:/Users/dylan/Work-Projects/msc_haar/manuscript1_exp/models/model_vgg16_bn_classifer_fixedfeatures.pth') \n",
    "        print(\"\\nMinimum Validation Loss of {:.4f} at epoch {}/{}\".format(loss_min, epoch, num_epochs))\n",
    "        print('Model Saved\\n')\n",
    "print('Training Complete')\n",
    "print(\"Total Elapsed Time : {} s\".format(time.time()-start_time))\n",
    "results['time'].append(time.time()-start_time)\n",
    "del(network)\n",
    "del(images)\n",
    "del(targets)\n",
    "del(predictions)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "f = open(\"model_vgg16_bn_classifer_fixedfeatures_trainingdata.pkl\",\"wb\")\n",
    "pickle.dump(results,f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "25026d616bab744e6e2aa9f0658a0c2cb295ef74a9318d75c9b54e5a9a85152d"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "7ec889e55d6cc5b8bc0c6d4c97764aa47dfaa2c194dbff749325c0fada24bc92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
